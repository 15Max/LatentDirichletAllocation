{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded Topic Model (ETM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicovis/anaconda3/envs/OCTIS/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import string\n",
    "import json\n",
    "from octis.preprocessing.preprocessing import Preprocessing\n",
    "from octis.models.ETM import ETM\n",
    "from octis.dataset.dataset import Dataset\n",
    "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
    "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
    "from octis.optimization.optimizer import Optimizer\n",
    "from skopt.space.space import Real, Integer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "os.chdir(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMALL = False\n",
    "\n",
    "model_path = 'model/cc.en.300.vec/cc.en.300.vec'\n",
    "\n",
    "if(SMALL):\n",
    "    frac = 0.001\n",
    "    data_path = 'data/input_small'\n",
    "    corpus_path = 'data/input_small/corpus.txt'\n",
    "    label_path = 'data/input_small/labels.txt'\n",
    "    proc_path = 'data/processed_small/dataset'\n",
    "    embeddings_path = 'data/embeddings/embeddings.pkl'\n",
    "else:\n",
    "    frac = 0.5\n",
    "    data_path = 'data/input'\n",
    "    corpus_path = 'data/input/corpus.txt'\n",
    "    label_path = 'data/input/labels.txt'\n",
    "    vocab_path = 'data/processed/dataset/vocabulary.txt'\n",
    "    proc_path = 'data/processed/dataset'\n",
    "    embeddings_path = 'data/embeddings_small/embeddings.pkl'\n",
    "\n",
    "\n",
    "dummy_run = False\n",
    "\n",
    "if(dummy_run):\n",
    "    num_iters = 5\n",
    "    number_of_calls = 2\n",
    "else:\n",
    "    num_iters = 50\n",
    "    number_of_calls = None # Depends on size of search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicovis/anaconda3/envs/OCTIS/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 11.0.0. Please consider upgrading.\n",
      "  warnings.warn(\n",
      "/home/nicovis/anaconda3/envs/OCTIS/lib/python3.9/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from utils.embeddings import *\n",
    "from preprocessing.clean_text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus has been saved to data/input/corpus.txt\n",
      "Labels have been saved to data/input/labels.txt\n"
     ]
    }
   ],
   "source": [
    "extract_corpus_and_labels_from_songs_csv(csv_input_path = 'data/raw/cleaned_train_lyrics.csv', output_path = data_path,frac=frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing(lowercase=True,\n",
    "                             min_df = 10,\n",
    "                             max_df = 0.85,\n",
    "                             remove_punctuation=True,\n",
    "                             punctuation=string.punctuation,\n",
    "                             remove_numbers=True,\n",
    "                             lemmatize= True,\n",
    "                             stopword_list=CUSTOM_STOPWORDS,\n",
    "                             min_chars=3,\n",
    "                             min_words_docs=10,\n",
    "                             language='english',\n",
    "                             split=True,\n",
    "                             verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249999/249999 [2:27:42<00:00, 28.21it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created vocab\n",
      "34731\n",
      "words filtering done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Checks if dataset folder exists in processed, if not it processes the dataset. Otherwise it loads it\n",
    "if not os.path.exists(proc_path):\n",
    "    dataset = preprocessor.preprocess_dataset(documents_path = corpus_path,labels_path = label_path)\n",
    "    dataset.save(proc_path)\n",
    "else:\n",
    "    dataset = Dataset()\n",
    "    dataset.load_custom_dataset_from_folder(proc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_documents': 249999,\n",
       " 'vocabulary_length': 34731,\n",
       " 'preprocessing-info': ['lowercase',\n",
       "  'remove_punctuation',\n",
       "  'lemmatize',\n",
       "  'filter words with document frequency lower than 10 and higher than 0.85',\n",
       "  'filter words with less than 3 character',\n",
       "  'filter documents with less than 10 words'],\n",
       " 'last-training-doc': 174636,\n",
       " 'last-validation-doc': 212059}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34731 words from data/processed/dataset/vocabulary.txt\n",
      "Loaded embeddings from model/cc.en.300.vec/cc.en.300.vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34731/34731 [00:03<00:00, 10633.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32384 relevant embeddings\n",
      "Saving relevant embeddings to data/embeddings_small/embeddings.pkl/embeddings.pkl\n",
      "Saved relevant embeddings to data/embeddings_small/embeddings.pkl/embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "embeddings = extract_relevant_embeddings(vocab_path = vocab_path,\n",
    "                                         model_path= model_path,\n",
    "                                         output_dir= embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETM model without optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using GPU: 0\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "N_TOPICS = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Currently using GPU: {current_device}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(current_device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ETM(num_topics= N_TOPICS,  \n",
    "        num_epochs=100, \n",
    "        t_hidden_size=200, \n",
    "        rho_size=300, \n",
    "        embedding_size=300,\n",
    "        activation='relu', \n",
    "        dropout=0.5, \n",
    "        lr=0.005, \n",
    "        optimizer='adam', \n",
    "        batch_size=64, \n",
    "        clip=0.0, \n",
    "        wdecay=1.2e-6, \n",
    "        bow_norm=1, \n",
    "        device=device, \n",
    "        train_embeddings=False, \n",
    "        embeddings_path= 'data/embeddings/embeddings.pkl',\n",
    "        embeddings_type='pickle', \n",
    "        use_partitions=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "td, ch = TopicDiversity(topk=10), Coherence(texts = dataset.get_corpus(), topk=10, measure = 'c_npmi') # Initialize metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: ETM(\n",
      "  (t_drop): Dropout(p=0.5, inplace=False)\n",
      "  (theta_act): ReLU()\n",
      "  (alphas): Linear(in_features=300, out_features=10, bias=False)\n",
      "  (q_theta): Sequential(\n",
      "    (0): Linear(in_features=34731, out_features=200, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (mu_q_theta): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (logsigma_q_theta): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Epoch: 1 .. batch: 20/2729 .. LR: 0.005 .. KL_theta: 0.22 .. Rec_loss: 1794.03 .. NELBO: 1794.25\n",
      "Epoch: 1 .. batch: 40/2729 .. LR: 0.005 .. KL_theta: 0.33 .. Rec_loss: 1732.77 .. NELBO: 1733.1\n",
      "Epoch: 1 .. batch: 60/2729 .. LR: 0.005 .. KL_theta: 0.41 .. Rec_loss: 1712.56 .. NELBO: 1712.97\n",
      "Epoch: 1 .. batch: 80/2729 .. LR: 0.005 .. KL_theta: 0.51 .. Rec_loss: 1708.08 .. NELBO: 1708.59\n",
      "Epoch: 1 .. batch: 100/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1711.03 .. NELBO: 1711.64\n",
      "Epoch: 1 .. batch: 120/2729 .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 1705.52 .. NELBO: 1706.15\n",
      "Epoch: 1 .. batch: 140/2729 .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 1705.12 .. NELBO: 1705.77\n",
      "Epoch: 1 .. batch: 160/2729 .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 1708.25 .. NELBO: 1708.91\n",
      "Epoch: 1 .. batch: 180/2729 .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 1699.81 .. NELBO: 1700.47\n",
      "Epoch: 1 .. batch: 200/2729 .. LR: 0.005 .. KL_theta: 0.66 .. Rec_loss: 1691.59 .. NELBO: 1692.25\n",
      "Epoch: 1 .. batch: 220/2729 .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 1688.24 .. NELBO: 1688.89\n",
      "Epoch: 1 .. batch: 240/2729 .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 1683.55 .. NELBO: 1684.2\n",
      "Epoch: 1 .. batch: 260/2729 .. LR: 0.005 .. KL_theta: 0.65 .. Rec_loss: 1683.11 .. NELBO: 1683.76\n",
      "Epoch: 1 .. batch: 280/2729 .. LR: 0.005 .. KL_theta: 0.64 .. Rec_loss: 1681.32 .. NELBO: 1681.96\n",
      "Epoch: 1 .. batch: 300/2729 .. LR: 0.005 .. KL_theta: 0.63 .. Rec_loss: 1681.24 .. NELBO: 1681.87\n",
      "Epoch: 1 .. batch: 320/2729 .. LR: 0.005 .. KL_theta: 0.62 .. Rec_loss: 1683.08 .. NELBO: 1683.7\n",
      "Epoch: 1 .. batch: 340/2729 .. LR: 0.005 .. KL_theta: 0.62 .. Rec_loss: 1679.01 .. NELBO: 1679.63\n",
      "Epoch: 1 .. batch: 360/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1677.29 .. NELBO: 1677.9\n",
      "Epoch: 1 .. batch: 380/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1674.22 .. NELBO: 1674.83\n",
      "Epoch: 1 .. batch: 400/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1677.23 .. NELBO: 1677.84\n",
      "Epoch: 1 .. batch: 420/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1676.12 .. NELBO: 1676.73\n",
      "Epoch: 1 .. batch: 440/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1675.24 .. NELBO: 1675.85\n",
      "Epoch: 1 .. batch: 460/2729 .. LR: 0.005 .. KL_theta: 0.61 .. Rec_loss: 1672.44 .. NELBO: 1673.05\n",
      "Epoch: 1 .. batch: 480/2729 .. LR: 0.005 .. KL_theta: 0.6 .. Rec_loss: 1672.85 .. NELBO: 1673.45\n",
      "Epoch: 1 .. batch: 500/2729 .. LR: 0.005 .. KL_theta: 0.6 .. Rec_loss: 1671.08 .. NELBO: 1671.68\n",
      "Epoch: 1 .. batch: 520/2729 .. LR: 0.005 .. KL_theta: 0.6 .. Rec_loss: 1670.93 .. NELBO: 1671.53\n",
      "Epoch: 1 .. batch: 540/2729 .. LR: 0.005 .. KL_theta: 0.6 .. Rec_loss: 1669.53 .. NELBO: 1670.13\n",
      "Epoch: 1 .. batch: 560/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1670.46 .. NELBO: 1671.05\n",
      "Epoch: 1 .. batch: 580/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1671.21 .. NELBO: 1671.8\n",
      "Epoch: 1 .. batch: 600/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1672.53 .. NELBO: 1673.12\n",
      "Epoch: 1 .. batch: 620/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1671.65 .. NELBO: 1672.24\n",
      "Epoch: 1 .. batch: 640/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1671.75 .. NELBO: 1672.34\n",
      "Epoch: 1 .. batch: 660/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1671.43 .. NELBO: 1672.02\n",
      "Epoch: 1 .. batch: 680/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1670.57 .. NELBO: 1671.16\n",
      "Epoch: 1 .. batch: 700/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1670.71 .. NELBO: 1671.3\n",
      "Epoch: 1 .. batch: 720/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1670.34 .. NELBO: 1670.93\n",
      "Epoch: 1 .. batch: 740/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.56 .. NELBO: 1669.15\n",
      "Epoch: 1 .. batch: 760/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.89 .. NELBO: 1669.48\n",
      "Epoch: 1 .. batch: 780/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.52 .. NELBO: 1669.11\n",
      "Epoch: 1 .. batch: 800/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.38 .. NELBO: 1668.97\n",
      "Epoch: 1 .. batch: 820/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.69 .. NELBO: 1669.28\n",
      "Epoch: 1 .. batch: 840/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.2 .. NELBO: 1668.79\n",
      "Epoch: 1 .. batch: 860/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1668.37 .. NELBO: 1668.95\n",
      "Epoch: 1 .. batch: 880/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1667.3 .. NELBO: 1667.89\n",
      "Epoch: 1 .. batch: 900/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1667.33 .. NELBO: 1667.91\n",
      "Epoch: 1 .. batch: 920/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1667.72 .. NELBO: 1668.3\n",
      "Epoch: 1 .. batch: 940/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1669.08 .. NELBO: 1669.66\n",
      "Epoch: 1 .. batch: 960/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.04 .. NELBO: 1668.63\n",
      "Epoch: 1 .. batch: 980/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1669.04 .. NELBO: 1669.62\n",
      "Epoch: 1 .. batch: 1000/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1668.44 .. NELBO: 1669.02\n",
      "Epoch: 1 .. batch: 1020/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.81 .. NELBO: 1669.4\n",
      "Epoch: 1 .. batch: 1040/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1668.04 .. NELBO: 1668.62\n",
      "Epoch: 1 .. batch: 1060/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1668.78 .. NELBO: 1669.37\n",
      "Epoch: 1 .. batch: 1080/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1668.85 .. NELBO: 1669.43\n",
      "Epoch: 1 .. batch: 1100/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1668.76 .. NELBO: 1669.34\n",
      "Epoch: 1 .. batch: 1120/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1668.12 .. NELBO: 1668.7\n",
      "Epoch: 1 .. batch: 1140/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1667.38 .. NELBO: 1667.96\n",
      "Epoch: 1 .. batch: 1160/2729 .. LR: 0.005 .. KL_theta: 0.59 .. Rec_loss: 1667.09 .. NELBO: 1667.68\n",
      "Epoch: 1 .. batch: 1180/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1666.52 .. NELBO: 1667.1\n",
      "Epoch: 1 .. batch: 1200/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1666.38 .. NELBO: 1666.96\n",
      "Epoch: 1 .. batch: 1220/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1665.45 .. NELBO: 1666.03\n",
      "Epoch: 1 .. batch: 1240/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1665.58 .. NELBO: 1666.16\n",
      "Epoch: 1 .. batch: 1260/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1665.32 .. NELBO: 1665.9\n",
      "Epoch: 1 .. batch: 1280/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.75 .. NELBO: 1665.33\n",
      "Epoch: 1 .. batch: 1300/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.81 .. NELBO: 1665.39\n",
      "Epoch: 1 .. batch: 1320/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.7 .. NELBO: 1665.28\n",
      "Epoch: 1 .. batch: 1340/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.34 .. NELBO: 1664.92\n",
      "Epoch: 1 .. batch: 1360/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.14 .. NELBO: 1664.72\n",
      "Epoch: 1 .. batch: 1380/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.07 .. NELBO: 1664.65\n",
      "Epoch: 1 .. batch: 1400/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1663.82 .. NELBO: 1664.4\n",
      "Epoch: 1 .. batch: 1420/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1664.16 .. NELBO: 1664.74\n",
      "Epoch: 1 .. batch: 1440/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1663.18 .. NELBO: 1663.76\n",
      "Epoch: 1 .. batch: 1460/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1663.93 .. NELBO: 1664.51\n",
      "Epoch: 1 .. batch: 1480/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1663.77 .. NELBO: 1664.35\n",
      "Epoch: 1 .. batch: 1500/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1663.42 .. NELBO: 1664.0\n",
      "Epoch: 1 .. batch: 1520/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1663.03 .. NELBO: 1663.61\n",
      "Epoch: 1 .. batch: 1540/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1662.54 .. NELBO: 1663.12\n",
      "Epoch: 1 .. batch: 1560/2729 .. LR: 0.005 .. KL_theta: 0.58 .. Rec_loss: 1662.55 .. NELBO: 1663.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [03:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 13.22 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m coherence_list_no_opt, topic_diversity_list_no_opt, iters \u001b[38;5;241m=\u001b[39m [], [], num_iters\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(iters)):\n\u001b[0;32m----> 4\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   coherence_list_no_opt\u001b[38;5;241m.\u001b[39mappend(ch_score \u001b[38;5;241m:=\u001b[39m ch\u001b[38;5;241m.\u001b[39mscore(output))\n\u001b[1;32m      6\u001b[0m   topic_diversity_list_no_opt\u001b[38;5;241m.\u001b[39mappend(td_score \u001b[38;5;241m:=\u001b[39m td\u001b[38;5;241m.\u001b[39mscore(output))\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/octis/models/ETM.py:93\u001b[0m, in \u001b[0;36mETM.train_model\u001b[0;34m(self, dataset, hyperparameters, top_words, op_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m     90\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, path\u001b[38;5;241m=\u001b[39mop_path)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 93\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/octis/models/ETM.py:180\u001b[0m, in \u001b[0;36mETM._train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    178\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m    179\u001b[0m                                    \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m acc_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(recon_loss)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    183\u001b[0m acc_kl_theta_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(kld_theta)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/torch/optim/adam.py:529\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    527\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_grads, device_params, alpha\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 529\u001b[0m         device_grads \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    530\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    534\u001b[0m torch\u001b[38;5;241m.\u001b[39m_foreach_lerp_(device_exp_avgs, device_grads, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 8.00 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 13.22 GiB is allocated by PyTorch, and 1.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "coherence_list_no_opt, topic_diversity_list_no_opt, iters = [], [], num_iters\n",
    "\n",
    "for i in tqdm(range(iters)):\n",
    "  output = model.train_model(dataset)\n",
    "  coherence_list_no_opt.append(ch_score := ch.score(output))\n",
    "  topic_diversity_list_no_opt.append(td_score := td.score(output))\n",
    "\n",
    "print(\"Mean coherence: \", np.mean(coherence_list_no_opt), \"\\nMean topic diversity: \", np.mean(topic_diversity_list_no_opt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ETM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization for hyperparameters based on coherence (to be substituted with a combination of ch e td ?)\n",
    "\n",
    "\n",
    "# Define the search space. To see which hyperparameters to optimize, see the topic model's initialization signature\n",
    "search_space = {\"num_topics\": Integer(low=5, high=50),\n",
    "                \"t_hidden_size\": Integer(low= 50, high=300),\n",
    "                \"lr\": Real(low=1e-4, high=1e-1)}\n",
    "\n",
    "# Initialize an optimizer object and start the optimization.\n",
    "optimizer=Optimizer()\n",
    "\n",
    "if(number_of_calls == None):\n",
    "    number_of_calls = len(search_space.keys())*5\n",
    "\n",
    "\n",
    "print(number_of_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the default optimization method (Bayesian optimization) and the default metric (coherence) to optimize the model, try also random search.\n",
    "\n",
    "optResult=optimizer.optimize(model, dataset, ch, search_space, save_path=\"results/test_LDA\", # path to store the results\n",
    "                            number_of_call=number_of_calls, # number of optimization iterations: rule of thumb 15*num_hyperparameters but takes a lot of time so 30 instead\n",
    "                            model_runs=5, # number of runs of the topic model: can be increased but takes more time\n",
    "                            plot_best_seen=True, # plot the best seen value of the metric\n",
    "                            extra_metrics = [td],\n",
    "                            plot_model=True, # plot the topic model\n",
    "                            early_step=10, # number of iterations after which the optimization stops if no improvement\n",
    "                            surrogate_model='GP', # surrogate model for the optimization: gaussian process\n",
    "                            random_state=123,\n",
    "                            save_models = True,\n",
    "                            topk=20)\n",
    "\n",
    "#save the results of th optimization in a csv file\n",
    "optResult.save_to_csv(\"results.csv\")\n",
    "\n",
    "results = json.load(open(\"results/test_LDA/result.json\",'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Coherence score (c_npmi)')\n",
    "plt.title('Median coherence score per iteration')\n",
    "plt.plot(results[\"f_val\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = results[\"f_val\"].index(max(results[\"f_val\"]))\n",
    "print(results[\"f_val\"][max_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results[\"x_iters\"].keys())\n",
    "\n",
    "num_topics = results[\"x_iters\"][\"num_topics\"][max_index]\n",
    "t_hidden_size = results[\"x_iters\"][\"t_hidden_size\"][max_index]\n",
    "lr = results[\"x_iters\"][\"lr\"][max_index]\n",
    "\n",
    "print(\"Optimal number of topics: \", num_topics)\n",
    "print(\"Optimal encoder hidden size: \", t_hidden_size)\n",
    "print(\"Optimal learning rate: \", lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ETM(num_topics= num_topics,  \n",
    "        num_epochs=100, \n",
    "        t_hidden_size=t_hidden_size, \n",
    "        rho_size=300, \n",
    "        embedding_size=300,\n",
    "        activation='relu', \n",
    "        dropout=0.5, \n",
    "        lr=lr, \n",
    "        optimizer='adam', \n",
    "        batch_size=64, \n",
    "        clip=0.0, \n",
    "        wdecay=1.2e-6, \n",
    "        bow_norm=1, \n",
    "        device=device, \n",
    "        train_embeddings=False, \n",
    "        embeddings_path= 'data/embeddings/embeddings.pkl',\n",
    "        embeddings_type='pickle', \n",
    "        use_partitions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_list, topic_diversity_list, iters = [], [], num_iters\n",
    "\n",
    "for i in range(iters):\n",
    "  output = model.train_model(dataset, top_words=20)\n",
    "  coherence_list.append(ch_score := ch.score(output))\n",
    "  topic_diversity_list.append(td_score := td.score(output))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Mean coherence: \", np.mean(coherence_list), \"\\nMean topic diversity: \", np.mean(topic_diversity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot of the coherences of the models (no opt vs opt) and the topic diversity of the models (no opt vs opt). Both plots also show the mean values and the variance!\n",
    "# Two plots side by side \n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Coherence scores plot\n",
    "axs[0].plot(coherence_list, label=\"Optimization\", color = 'orange', alpha = 0.4)\n",
    "axs[0].plot(coherence_list_no_opt, label=\"No optimization\", color = 'blue', alpha = 0.4)\n",
    "axs[0].axhline(y=np.mean(coherence_list), color='orange', linestyle=':')\n",
    "axs[0].axhline(y=np.mean(coherence_list_no_opt), color='blue', linestyle=':')\n",
    "axs[0].set_title(\"Coherence scores\")\n",
    "axs[0].set_xlabel(\"Training instances\")\n",
    "axs[0].set_ylabel(\"Coherence score\")\n",
    "axs[0].legend()\n",
    "\n",
    "# Topic diversity scores plot\n",
    "axs[1].plot(topic_diversity_list, label=\"Optimization\", color = 'r', alpha = 0.4)\n",
    "axs[1].plot(topic_diversity_list_no_opt, label=\"No optimization\", color = 'g', alpha = 0.4)\n",
    "axs[1].axhline(y=np.mean(topic_diversity_list), color='r', linestyle=':')\n",
    "axs[1].axhline(y=np.mean(topic_diversity_list_no_opt), color='g', linestyle=':')\n",
    "axs[1].set_title(\"Topic diversity scores\")\n",
    "axs[1].set_xlabel(\"Traning instances\")\n",
    "axs[1].set_ylabel(\"Topic diversity score\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OCTIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
