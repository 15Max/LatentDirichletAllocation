{"dataset_name": "BBC_News", "dataset_path": "/home/nicovis/octis_data/BBC_News_py3.pkz", "is_cached": true, "kernel": "1**2 * Matern(length_scale=1, nu=1.5)", "acq_func": "LCB", "surrogate_model": "GP", "optimization_type": "Maximize", "model_runs": 5, "save_models": true, "save_step": 1, "save_name": "result", "save_path": "results/test_LDA/", "early_stop": false, "early_step": 10, "plot_model": true, "plot_best_seen": true, "plot_name": "B0_plot", "log_scale_plot": false, "search_space": {"num_topics": ["Integer", [5, 50], "uniform"], "offset": ["Integer", [1, 100], "uniform"]}, "model_name": "LDA", "model_attributes": {"distributed": false, "chunksize": 2000, "passes": 1, "update_every": 1, "alpha": "symmetric", "decay": 0.5, "eval_every": 10, "iterations": 50, "gamma_threshold": 0.001}, "use_partitioning": true, "metric_name": "Coherence", "extra_metric_names": [], "metric_attributes": {"measure": "c_v", "processes": 1, "topk": 10}, "extra_metric_attributes": {}, "current_call": 29, "number_of_call": 30, "random_state": 123, "x0": {}, "y0": [], "n_random_starts": 1, "initial_point_generator": "lhs", "topk": 10, "time_eval": [25.47213649749756, 13.931931257247925, 14.10600996017456, 13.905146598815918, 31.816595315933228, 20.3632915019989, 13.969141721725464, 16.29845905303955, 13.972935199737549, 35.15362763404846, 23.332985639572144, 16.608333110809326, 36.9701509475708, 15.247783184051514, 18.87639808654785, 14.167878150939941, 26.005112409591675, 39.530476331710815, 15.918895721435547, 24.115026235580444, 14.100399017333984, 15.398885726928711, 23.56792950630188, 18.785136461257935, 14.19338083267212, 28.274510383605957, 33.54616045951843, 17.15577268600464, 13.811510801315308, 27.1123948097229], "dict_model_runs": {"Coherence": {"iteration_0": [0.3997553441780284, 0.39762241355264644, 0.3984511382936026, 0.42272380813104005, 0.3946249792621152], "iteration_1": [0.40818877651996227, 0.4086768592013047, 0.40532450081826177, 0.40641014976116985, 0.41477726573095985], "iteration_2": [0.4090716799613713, 0.41889465518875174, 0.4082584585718922, 0.41633229034747765, 0.39385802804741854], "iteration_3": [0.41365387831150624, 0.40179328884692483, 0.40801109224592824, 0.4129111577743145, 0.40629896755142914], "iteration_4": [0.39788183366299096, 0.4028986893486978, 0.4215310043809764, 0.3909303951340802, 0.40551294643054336], "iteration_5": [0.39889279869090144, 0.41254809387256763, 0.402914503227007, 0.4292844298275246, 0.40532780647427186], "iteration_6": [0.4136972219053683, 0.40412663905015983, 0.4293476698273202, 0.423706542383424, 0.3920220231566439], "iteration_7": [0.4139403896751961, 0.4099827245884629, 0.41163448231776767, 0.4107060768211943, 0.4184578927874037], "iteration_8": [0.397406068858536, 0.4092476253304098, 0.4286509689295537, 0.4205412267946289, 0.39660448829628875], "iteration_9": [0.40322551270843693, 0.40083774401884886, 0.3994173665729055, 0.4030397698887514, 0.413670163740152], "iteration_10": [0.40046439733576317, 0.40583567175284435, 0.3886033131742657, 0.3891438205203807, 0.39820877164955454], "iteration_11": [0.4088990093821514, 0.41413751209435246, 0.39657694587823844, 0.399107180423459, 0.40750780767660727], "iteration_12": [0.3996121043651272, 0.3899486934978431, 0.4081658081279002, 0.4034083668327399, 0.3997631766333203], "iteration_13": [0.40666726516828106, 0.38995120423099827, 0.4073563244466238, 0.42047671309547324, 0.4084164839458661], "iteration_14": [0.38771398858035255, 0.39437161006701094, 0.4003268087477785, 0.4173739833321406, 0.4083984756611264], "iteration_15": [0.4239535743627398, 0.4128552599823916, 0.41697205708813456, 0.40185547154806606, 0.39681966619010023], "iteration_16": [0.4058712803610599, 0.40290404085756076, 0.39587200173759496, 0.4074542133916579, 0.409795690246148], "iteration_17": [0.4040404982833497, 0.3948698540952412, 0.40807459817385805, 0.40343177551162457, 0.40235638552056957], "iteration_18": [0.403798840273116, 0.3983501422497403, 0.4086599231689185, 0.41235365153604686, 0.4025072677747797], "iteration_19": [0.41032872887844735, 0.4082554392760752, 0.4088963446229233, 0.39914542111935813, 0.415194040835525], "iteration_20": [0.4127039139352222, 0.4156644946848382, 0.4222575741800873, 0.41070505279719927, 0.4174109900689585], "iteration_21": [0.4254964434392935, 0.4018260080737886, 0.4367229130011173, 0.3954423283883407, 0.4092126688794342], "iteration_22": [0.4101938488467186, 0.4018462408882801, 0.40546284130517246, 0.40304557820022774, 0.3993041554211882], "iteration_23": [0.41775760357383485, 0.39682745136830083, 0.4022122184532146, 0.4114618541940644, 0.39977899651151233], "iteration_24": [0.39970346185134875, 0.39363219805271027, 0.4067555046243486, 0.432150860932836, 0.4199242050281747], "iteration_25": [0.40391656703392886, 0.4016449077275956, 0.40380680066509067, 0.4014981231923012, 0.4062336560514095], "iteration_26": [0.3999399927590516, 0.39191000375254065, 0.40879662191675736, 0.4039360512985165, 0.41478528845043205], "iteration_27": [0.4196621610339777, 0.40683654830850347, 0.40871227521122855, 0.40383294665321956, 0.41219736002260426], "iteration_28": [0.4095930947445156, 0.4282309555216294, 0.411262648105487, 0.39033349445548227, 0.40995598818664203], "iteration_29": [0.41032061343014714, 0.4042551790587347, 0.40249336025748106, 0.404900509085211, 0.4036184945873379]}}, "f_val": [0.3984511382936026, 0.40818877651996227, 0.4090716799613713, 0.40801109224592824, 0.4028986893486978, 0.40532780647427186, 0.4136972219053683, 0.41163448231776767, 0.4092476253304098, 0.4030397698887514, 0.39820877164955454, 0.40750780767660727, 0.3997631766333203, 0.4073563244466238, 0.4003268087477785, 0.4128552599823916, 0.4058712803610599, 0.40343177551162457, 0.403798840273116, 0.4088963446229233, 0.4156644946848382, 0.4092126688794342, 0.40304557820022774, 0.4022122184532146, 0.4067555046243486, 0.40380680066509067, 0.4039360512985165, 0.40871227521122855, 0.40995598818664203, 0.4042551790587347], "x_iters": {"num_topics": [38, 5, 5, 5, 50, 24, 5, 13, 5, 49, 28, 14, 50, 8, 21, 5, 38, 50, 11, 36, 5, 8, 27, 19, 5, 40, 50, 15, 5, 40], "offset": [59, 1, 99, 51, 1, 1, 80, 80, 73, 100, 100, 27, 41, 87, 60, 24, 13, 76, 10, 1, 35, 35, 23, 83, 32, 90, 19, 100, 13, 35]}}