{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latent Dirichlet Allocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgmokdyEiRlV"
      },
      "outputs": [],
      "source": [
        "from octis.models.LDA import LDA\n",
        "from octis.dataset.dataset import Dataset\n",
        "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
        "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
        "from octis.optimization.optimizer import Optimizer\n",
        "from skopt.space.space import Integer\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_ITERS = 15\n",
        "NUM_OPTIMIZATION_CALLS = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder('data/processed/dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_ITERS = 15\n",
        "NUM_OPTIMIZATION_CALLS = 15 # Bottleneck for computation time 10m calls approx 3 hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "td, ch = TopicDiversity(topk=10), Coherence(texts = dataset.get_corpus(), topk= 10, measure = 'c_v') # Initialize metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Without optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC5N5nLBiRlW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Create Model, our  arbitrary assumption on the initial number of topics: 10 \n",
        "model = LDA(num_topics=5, alpha = 'auto', passes= 50, iterations = 200, update_every = 1, chunksize = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coherence_list_no_opt, topic_diversity_list_no_opt = [], []\n",
        "\n",
        "for i in tqdm(range(NUM_ITERS)):\n",
        "  output = model.train_model(dataset)\n",
        "  coherence_list_no_opt.append(ch_score := ch.score(output))\n",
        "  topic_diversity_list_no_opt.append(td_score := td.score(output))\n",
        "\n",
        "print(\"Mean coherence: \", np.mean(coherence_list_no_opt), \"\\nMean topic diversity: \", np.mean(topic_diversity_list_no_opt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LDA(alpha = 'auto', passes= 50, iterations = 200, update_every = 1, chunksize = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimization for hyperparameters based on coherence\n",
        "\n",
        "search_space = {\"num_topics\": Integer(low=5, high=35)}\n",
        "optimizer=Optimizer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "start = time.time() # Just to see, to be removed.\n",
        "\n",
        "# This uses the default optimization method (Bayesian optimization) and the default metric (coherence) to optimize the model, try also random search.\n",
        "\n",
        "optResult = optimizer.optimize(model, dataset, ch, search_space, save_path=\"results/test_LDA\", # path to store the results\n",
        "                            number_of_call = NUM_OPTIMIZATION_CALLS, # number of optimization iterations: rule of thumb 15*num_hyperparameters but takes a lot of time so 30 instead\n",
        "                            model_runs = 5, # number of runs of the topic model: can be increased but takes more time\n",
        "                            plot_best_seen = True, # plot the best seen value of the metric\n",
        "                            extra_metrics = [td], # track also the topic diversity\n",
        "                            plot_model = True, # plot the topic model\n",
        "                            early_step = 10, # number of iterations after which the optimization stops if no improvement\n",
        "                            surrogate_model ='GP', # surrogate model for the optimization: gaussian process\n",
        "                            save_models = True,\n",
        "                            topk = 20)\n",
        "\n",
        "#save the results of th optimization in a csv file\n",
        "optResult.save_to_csv(\"results.csv\")\n",
        "\n",
        "end = time.time()\n",
        "duration = end - start\n",
        "\n",
        "print('Optimizing model took: ' + str(round(duration)) + ' seconds.')\n",
        "results = json.load(open(\"results/test_LDA/result.json\",'r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Coherence score (c_v)')\n",
        "plt.title('Mean coherence score per iteration')\n",
        "\n",
        "coherences = results['dict_model_runs']['Coherence']\n",
        "\n",
        "mean_coherences = [np.mean(coherences[key]) for key in coherences.keys()]\n",
        "\n",
        "plt.plot(mean_coherences)\n",
        "plt.xticks(range(len(mean_coherences)))\n",
        "plt.show()\n",
        "\n",
        "print(np.max(mean_coherences))\n",
        "\n",
        "max_index = np.argmax(mean_coherences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(results[\"x_iters\"].keys())\n",
        "\n",
        "num_topics = results[\"x_iters\"][\"num_topics\"][max_index]]\n",
        "\n",
        "print(\"Optimal number of topics: \", num_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky2sTIyIlO28"
      },
      "source": [
        "Now we're ready to train it. Note that the output of a topic model comes as a dictionary composed of 4 elements:\n",
        "\n",
        "\n",
        "*   *topics*: the list of word topics\n",
        "*   *topic-word-matrix*: the distribution of the words of the vocabulary for each topic (dimensions: |num topics| x |vocabulary|)\n",
        "*   *topic-document-matrix*: the distribution of the topics for each document of the training set (dimensions: |num topics| x |training documents|)\n",
        "*   *test-document-topic-matrix*: the distribution of the topics for each document of the testing set (dimensions: |num topics| x |test documents|)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LDA(num_topics = num_topics, alpha = 'auto', passes= 50, iterations = 200, update_every = 1, chunksize = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dCL2fAOiRlZ",
        "outputId": "e57ce766-899c-42f3-8c7d-76b7cc4e79fc"
      },
      "outputs": [],
      "source": [
        "coherence_list, topic_diversity_list, outputs = [], [], []\n",
        "\n",
        "for i in tqdm(range(NUM_ITERS)):\n",
        "  output = model.train_model(dataset, top_words=10)\n",
        "  outputs.append(output)\n",
        "  coherence_list.append(ch_score := ch.score(output))\n",
        "  topic_diversity_list.append(td_score := td.score(output))\n",
        "\n",
        "\n",
        "print(\"Mean coherence: \", np.mean(coherence_list), \"\\nMean topic diversity: \", np.mean(topic_diversity_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Plot of the coherences of the models (no opt vs opt) and the topic diversity of the models (no opt vs opt). Both plots also show the mean values and the variance!\n",
        "# Two plots side by side \n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Coherence scores plot\n",
        "axs[0].plot(coherence_list, label=\"Optimization\", color = 'orange', alpha = 0.4)\n",
        "axs[0].plot(coherence_list_no_opt, label=\"No optimization\", color = 'blue', alpha = 0.4)\n",
        "axs[0].axhline(y=np.mean(coherence_list), color='orange', linestyle=':')\n",
        "axs[0].axhline(y=np.mean(coherence_list_no_opt), color='blue', linestyle=':')\n",
        "axs[0].set_title(\"Coherence scores\")\n",
        "axs[0].set_xlabel(\"Training instances\")\n",
        "axs[0].set_ylabel(\"Coherence score c_v\")\n",
        "axs[0].legend()\n",
        "\n",
        "# Topic diversity scores plot\n",
        "axs[1].plot(topic_diversity_list, label=\"Optimization\", color = 'r', alpha = 0.4)\n",
        "axs[1].plot(topic_diversity_list_no_opt, label=\"No optimization\", color = 'g', alpha = 0.4)\n",
        "axs[1].axhline(y=np.mean(topic_diversity_list), color='r', linestyle=':')\n",
        "axs[1].axhline(y=np.mean(topic_diversity_list_no_opt), color='g', linestyle=':')\n",
        "axs[1].set_title(\"Topic diversity scores\")\n",
        "axs[1].set_xlabel(\"Traning instances\")\n",
        "axs[1].set_ylabel(\"Topic diversity score\")\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the best output from the outputs list according to a linear combination of the coherence and topic diversity scores\n",
        "\n",
        "best_output = outputs[np.argmax([0.7*coherence_list[i] + 0.3*topic_diversity_list[i] for i in range(len(coherence_list))])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics = best_output['topics']\n",
        "for i, topic in enumerate(topics):\n",
        "  wordcloud = WordCloud(width=500, height=400, background_color='white').generate(\" \".join(topic))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"Topic {i}\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_frequencies_barplot_dict(best_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = best_output['topic-word-matrix']\n",
        "\n",
        "print(np.shape(a))\n",
        "\n",
        "print(np.argmax(a[0]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LDA_training_only.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "OCTIS",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
