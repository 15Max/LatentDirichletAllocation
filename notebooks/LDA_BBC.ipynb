{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Latent Dirichlet Allocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xgmokdyEiRlV"
      },
      "outputs": [],
      "source": [
        "from octis.models.LDA import LDA\n",
        "from octis.dataset.dataset import Dataset\n",
        "from octis.evaluation_metrics.diversity_metrics import TopicDiversity\n",
        "from octis.evaluation_metrics.coherence_metrics import Coherence\n",
        "from octis.optimization.optimizer import Optimizer\n",
        "from skopt.space.space import Integer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import os\n",
        "from wordcloud import WordCloud\n",
        "from tqdm import tqdm\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "parent_directory = os.path.dirname(current_directory)\n",
        "os.chdir(parent_directory)\n",
        "\n",
        "from utils.graph_tools import word_frequencies_barplot_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_ITERS = 15\n",
        "NUM_OPTIMIZATION_CALLS = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = Dataset()\n",
        "dataset.load_custom_dataset_from_folder('data/processed/dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "td, ch = TopicDiversity(topk=10), Coherence(texts = dataset.get_corpus(), topk= 10, measure = 'c_v') # Initialize metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LDA without optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CC5N5nLBiRlW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Create Model, our  arbitrary assumption on the initial number of topics: 10 \n",
        "model = LDA(num_topics=5, alpha = 'auto', passes= 50, iterations = 200, update_every = 1, chunksize = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 9/15 [05:22<03:35, 35.86s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m coherence_list_no_opt, topic_diversity_list_no_opt \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(NUM_ITERS)):\n\u001b[0;32m----> 4\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m   coherence_list_no_opt\u001b[38;5;241m.\u001b[39mappend(ch_score \u001b[38;5;241m:=\u001b[39m ch\u001b[38;5;241m.\u001b[39mscore(output))\n\u001b[1;32m      6\u001b[0m   topic_diversity_list_no_opt\u001b[38;5;241m.\u001b[39mappend(td_score \u001b[38;5;241m:=\u001b[39m td\u001b[38;5;241m.\u001b[39mscore(output))\n",
            "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/octis/models/LDA.py:195\u001b[0m, in \u001b[0;36mLDA.train_model\u001b[0;34m(self, dataset, hyperparams, top_words)\u001b[0m\n\u001b[1;32m    192\u001b[0m hyperparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid2word\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid2word\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters\u001b[38;5;241m.\u001b[39mupdate(hyperparams)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_model \u001b[38;5;241m=\u001b[39m \u001b[43mldamodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    199\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic-word-matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrained_model\u001b[38;5;241m.\u001b[39mget_topics()\n",
            "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/gensim/models/ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/gensim/models/ldamodel.py:1006\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1002\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1003\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: pass \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, at document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1004\u001b[0m         pass_, chunk_no \u001b[38;5;241m*\u001b[39m chunksize \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk), lencorpus\n\u001b[1;32m   1005\u001b[0m     )\n\u001b[0;32m-> 1006\u001b[0m     gammat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_alpha:\n\u001b[1;32m   1009\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_alpha(gammat, rho())\n",
            "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/gensim/models/ldamodel.py:768\u001b[0m, in \u001b[0;36mLdaModel.do_estep\u001b[0;34m(self, chunk, state)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    767\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[0;32m--> 768\u001b[0m gamma, sstats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_sstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m state\u001b[38;5;241m.\u001b[39msstats \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sstats\n\u001b[1;32m    770\u001b[0m state\u001b[38;5;241m.\u001b[39mnumdocs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# avoids calling len(chunk) on a generator\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/envs/OCTIS/lib/python3.9/site-packages/gensim/models/ldamodel.py:719\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    715\u001b[0m lastgamma \u001b[38;5;241m=\u001b[39m gammad\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# We represent phi implicitly to save memory and time.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# Substituting the value of the optimal phi back into\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;66;03m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[39;00m\n\u001b[0;32m--> 719\u001b[0m gammad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m+\u001b[39m expElogthetad \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[43mcts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphinorm\u001b[49m, expElogbetad\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m    720\u001b[0m Elogthetad \u001b[38;5;241m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[1;32m    721\u001b[0m expElogthetad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(Elogthetad)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "coherence_list_no_opt, topic_diversity_list_no_opt, models_no_opt = [], [], []\n",
        "\n",
        "for i in tqdm(range(NUM_ITERS)):\n",
        "  output = model.train_model(dataset)\n",
        "  models_no_opt.append(output)\n",
        "  coherence_list_no_opt.append(ch_score := ch.score(output))\n",
        "  topic_diversity_list_no_opt.append(td_score := td.score(output))\n",
        "\n",
        "print(\"Mean coherence: \", np.mean(coherence_list_no_opt), \"\\nMean topic diversity: \", np.mean(topic_diversity_list_no_opt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LDA with optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LDA(alpha = 'auto', passes= 50, iterations = 200, update_every = 1, chunksize = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optimization for hyperparameters based on coherence\n",
        "\n",
        "search_space = {\"num_topics\": Integer(low=5, high=35)}\n",
        "optimizer=Optimizer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optResult = optimizer.optimize(model, dataset, ch, search_space, save_path=\"results/test_LDA\", # path to store the results\n",
        "                            number_of_call = NUM_OPTIMIZATION_CALLS, # number of optimization iterations: rule of thumb 15*num_hyperparameters but takes a lot of time so 30 instead\n",
        "                            model_runs = 5, # number of runs of the topic model: can be increased but takes more time\n",
        "                            plot_best_seen = True, # plot the best seen value of the metric\n",
        "                            extra_metrics = [td], # track also the topic diversity\n",
        "                            plot_model = True, # plot the topic model\n",
        "                            early_step = 10, # number of iterations after which the optimization stops if no improvement\n",
        "                            surrogate_model ='GP', # surrogate model for the optimization: gaussian process\n",
        "                            save_models = True,\n",
        "                            topk = 20)\n",
        "\n",
        "\n",
        "optResult.save_to_csv(\"results.csv\")\n",
        "\n",
        "results = json.load(open(\"results/test_LDA/result.json\",'r'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Coherence score (c_v)')\n",
        "plt.title('Mean coherence score per iteration')\n",
        "\n",
        "coherences = results['dict_model_runs']['Coherence']\n",
        "\n",
        "mean_coherences = [np.mean(coherences[key]) for key in coherences.keys()]\n",
        "\n",
        "plt.plot(mean_coherences)\n",
        "plt.xticks(range(len(mean_coherences)))\n",
        "plt.show()\n",
        "\n",
        "print(np.max(mean_coherences))\n",
        "\n",
        "max_index = np.argmax(mean_coherences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_topics = results[\"x_iters\"][\"num_topics\"][max_index]\n",
        "\n",
        "print(\"Optimal number of topics: \", num_topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky2sTIyIlO28"
      },
      "source": [
        "Now we're ready to train it. Note that the output of a topic model comes as a dictionary composed of 4 elements:\n",
        "\n",
        "\n",
        "*   *topics*: the list of word topics\n",
        "*   *topic-word-matrix*: the distribution of the words of the vocabulary for each topic (dimensions: |num topics| x |vocabulary|)\n",
        "*   *topic-document-matrix*: the distribution of the topics for each document of the training set (dimensions: |num topics| x |training documents|)\n",
        "*   *test-document-topic-matrix*: the distribution of the topics for each document of the testing set (dimensions: |num topics| x |test documents|)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LDA(num_topics = num_topics, alpha = 'auto', passes= 50, iterations = 200, update_every = 1, chunksize = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dCL2fAOiRlZ",
        "outputId": "e57ce766-899c-42f3-8c7d-76b7cc4e79fc"
      },
      "outputs": [],
      "source": [
        "coherence_list, topic_diversity_list, models_opt = [], [], []\n",
        "\n",
        "for i in tqdm(range(NUM_ITERS)):\n",
        "  output = model.train_model(dataset, top_words=10)\n",
        "  models_opt.append(output)\n",
        "  coherence_list.append(ch_score := ch.score(output))\n",
        "  topic_diversity_list.append(td_score := td.score(output))\n",
        "\n",
        "\n",
        "print(\"Mean coherence: \", np.mean(coherence_list), \"\\nMean topic diversity: \", np.mean(topic_diversity_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Coherence scores plot\n",
        "axs[0].plot(coherence_list, label=\"Optimization\", color = 'orange', alpha = 0.4)\n",
        "axs[0].plot(coherence_list_no_opt, label=\"No optimization\", color = 'blue', alpha = 0.4)\n",
        "axs[0].axhline(y=np.mean(coherence_list), color='orange', linestyle=':')\n",
        "axs[0].axhline(y=np.mean(coherence_list_no_opt), color='blue', linestyle=':')\n",
        "axs[0].set_title(\"Coherence scores\")\n",
        "axs[0].set_xlabel(\"Training instances\")\n",
        "axs[0].set_ylabel(\"Coherence score c_v\")\n",
        "axs[0].legend()\n",
        "\n",
        "# Topic diversity scores plot\n",
        "axs[1].plot(topic_diversity_list, label=\"Optimization\", color = 'r', alpha = 0.4)\n",
        "axs[1].plot(topic_diversity_list_no_opt, label=\"No optimization\", color = 'g', alpha = 0.4)\n",
        "axs[1].axhline(y=np.mean(topic_diversity_list), color='r', linestyle=':')\n",
        "axs[1].axhline(y=np.mean(topic_diversity_list_no_opt), color='g', linestyle=':')\n",
        "axs[1].set_title(\"Topic diversity scores\")\n",
        "axs[1].set_xlabel(\"Traning instances\")\n",
        "axs[1].set_ylabel(\"Topic diversity score\")\n",
        "axs[1].legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "outputs = models_no_opt + models_opt\n",
        "\n",
        "best_output = outputs[np.argmax([0.7*coherence_list[i] + 0.3*topic_diversity_list[i] for i in range(len(coherence_list))])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics = best_output['topics']\n",
        "for i, topic in enumerate(topics):\n",
        "  wordcloud = WordCloud(width=500, height=400, background_color='white').generate(\" \".join(topic))\n",
        "  plt.figure(figsize=(10, 5))\n",
        "  plt.imshow(wordcloud, interpolation='bilinear')\n",
        "  plt.axis('off')\n",
        "  plt.title(f\"Topic {i}\")\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_frequencies_barplot_dict(best_output)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "LDA_training_only.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "OCTIS",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
